{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><div align='center'>Web Scraping Wikipedia using BeautifulSoup and Python</div></h3>\n",
    "\n",
    "<div align='center'>Camille COCHENER</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>https://secouchermoinsbete.fr/69863-tous-les-chemins-menent-a-la-philosophie-sur-wikipedia : </div>  \n",
    "  \n",
    "*<div align='center'>« Une théorie veut que n'importe quel article sur Wikipedia pointe au final sur la philosophie. Pour la vérifier, il suffit de cliquer sur le premier lien d'un article Wikipedia qui mène à un autre article et ainsi de suite : à force, on tombe immanquablement sur l'article dédié à la philosophie. »  </div>* \n",
    "  \n",
    "<div align='justify'>Ecrivons un programme qui vérifie cette théorie. Ce programme doit renvoyer la \"distance\" (int) qui sépare un article donné de l'article Philosophie.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Source : https://github.com/wblakecannon/udacity-dand/blob/master/Ex6-Intro-to-Python-Programming/wiki-web-crawl/wikipedia-crawler.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation des librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import requests\n",
    "import quopri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Définition de l'url de départ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_url = \"https://fr.wikipedia.org/wiki/Glace\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://fr.wikipedia.org/wiki/Glace\n",
      "https://fr.wikipedia.org/wiki/Eau\n",
      "https://fr.wikipedia.org/wiki/Substance_chimique\n",
      "https://fr.wikipedia.org/wiki/%C3%89chantillon_(mati%C3%A8re)\n",
      "https://fr.wikipedia.org/wiki/Liste_de_propri%C3%A9t%C3%A9s_de_mat%C3%A9riaux\n",
      "https://fr.wikipedia.org/wiki/Grandeur_intensive\n",
      "https://fr.wikipedia.org/wiki/Grandeur_physique\n",
      "https://fr.wikipedia.org/wiki/Science_de_la_nature\n",
      "https://fr.wikipedia.org/wiki/Monde_(univers)\n",
      "https://fr.wikipedia.org/wiki/Donn%C3%A9es\n",
      "https://fr.wikipedia.org/wiki/Donn%C3%A9es_brutes\n",
      "We've arrived at an article we've already seen, aborting search!\n",
      "La distance parcourue entre ces 2 articles est : 11\n"
     ]
    }
   ],
   "source": [
    "def find_first_link(url):\n",
    "    response = requests.get(url) \n",
    "    html = response.text\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    # This div contains the article's body\n",
    "    content_div = soup.find(id=\"mw-content-text\").find(class_=\"mw-parser-output\")\n",
    "\n",
    "    # stores the first link found in the article, if the article contains no\n",
    "    # links this value will remain None\n",
    "    article_link = None # on initialise le lien suivant à none\n",
    "\n",
    "    # Find all the direct children of content_div that are paragraphs\n",
    "    for element in content_div.find_all(\"p\", recursive=False):\n",
    "        # Find the first anchor tag that's a direct child of a paragraph.\n",
    "        # It's important to only look at direct children, because other types\n",
    "        # of link, e.g. footnotes and pronunciation, could come before the\n",
    "        # first link to an article. Those other link types aren't direct\n",
    "        # children though, they're in divs of various classes.\n",
    "        \n",
    "        # on parcourt les éléments de la page et on cherche les liens les uns après les autres\n",
    "        \n",
    "        if element.find(\"a\", recursive=False):\n",
    "            article_link = element.find(\"a\", recursive=False).get('href')\n",
    "            break\n",
    "\n",
    "    if not article_link:\n",
    "        return\n",
    "\n",
    "    # Build a full url from the relative article_link url\n",
    "    first_link = urllib.parse.urljoin(\n",
    "        'https://fr.wikipedia.org/', article_link)\n",
    "\n",
    "    return first_link\n",
    "\n",
    "\n",
    "def continue_crawl(search_history, target_url, max_steps=25):\n",
    "    # pour chaque lien trouvé, on regarde s'il s'agit du lien philosophie que l'on cherche.\n",
    "    if search_history[-1] == target_url:\n",
    "        print(\"We've found the target article!\")\n",
    "        return False\n",
    "        # on pose une limite à la recherche\n",
    "    elif len(search_history) > max_steps:\n",
    "        print(\"The search has gone on suspiciously long, aborting search!\")\n",
    "        return False\n",
    "        # on vérifie si le lien récupéré a déjà été parcouru\n",
    "    elif search_history[-1] in search_history[:-1]:\n",
    "        print(\"We've arrived at an article we've already seen, aborting search!\")\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "def getting_to_philosophy(my_url): \n",
    "    article_chain = [my_url]\n",
    "    target_url = \"https://fr.wikipedia.org/wiki/Philosophie\"\n",
    "    while continue_crawl(article_chain, target_url):\n",
    "        print(article_chain[-1])\n",
    "        first_link = find_first_link(article_chain[-1])\n",
    "        if not first_link:\n",
    "            print(\"We've arrived at an article with no links, aborting search!\")\n",
    "            break\n",
    "        article_chain.append(first_link)\n",
    "        time.sleep(2)  # Slow things down so as to not hammer Wikipedia's servers\n",
    "    print('La distance parcourue entre ces 2 articles est : ' + str(len(article_chain)-1))\n",
    "\n",
    "        \n",
    "def main():\n",
    "  getting_to_philosophy(my_url)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
