{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><div align='center'>Web Scraping Wikipedia using BeautifulSoup and Python</div></h3>\n",
    "\n",
    "<div align='center'>Camille COCHENER</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align='justify'>https://secouchermoinsbete.fr/69863-tous-les-chemins-menent-a-la-philosophie-sur-wikipedia : </div>  \n",
    "  \n",
    "*<div align='center'>« Une théorie veut que n'importe quel article sur Wikipedia pointe au final sur la philosophie. Pour la vérifier, il suffit de cliquer sur le premier lien d'un article Wikipedia qui mène à un autre article et ainsi de suite : à force, on tombe immanquablement sur l'article dédié à la philosophie. »  </div>* \n",
    "  \n",
    "<div align='justify'>Ecrivons un programme qui vérifie cette théorie. Ce programme doit renvoyer la \"distance\" (int) qui sépare un article donné de l'article Philosophie.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importation des librairies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import urllib\n",
    "import bs4\n",
    "import requests\n",
    "import quopri\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Première fonction qui trouve le premier lien d'un article dans une page wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_first_link(url):\n",
    "    # Récupère le contenu de la page\n",
    "    response = requests.get(url).text \n",
    "    # Parse le contenu dans un objet BeautifulSoup\n",
    "    soup = bs4.BeautifulSoup(response, \"html.parser\") \n",
    "\n",
    "    # Trouve les \n",
    "    links = soup.find(id=\"mw-content-text\").find(class_=\"mw-parser-output\") \n",
    "\n",
    "    article_link = None\n",
    "\n",
    "    for link in links.find_all(\"p\", recursive=False):\n",
    "        \n",
    "        if link.find(\"a\", recursive=False):\n",
    "            article_link = link.find(\"a\", recursive=False).get('href')\n",
    "            break\n",
    "\n",
    "    if not article_link:\n",
    "        return\n",
    "\n",
    "    # Création de l'url\n",
    "    first_link = urllib.parse.urljoin('https://fr.wikipedia.org/', article_link)\n",
    "\n",
    "    return first_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deuxième fonction pour parcourir les articles trouvés**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def continuer(curr_links, target_url, max_iter=25):\n",
    "    \n",
    "    # Dès qu'on trouve l'article Philosophie, on arrête\n",
    "    if curr_links[-1] == target_url:\n",
    "        print(\"Nous avons atteint l'article Philosophie\")\n",
    "        return False\n",
    "\n",
    "    # Pour éviter que l'algorithme tourne trop longtemps:\n",
    "    elif len(curr_links) > max_iter:\n",
    "        print(\"La recherche est anormalement longue, on arrête le job!\")\n",
    "        return False\n",
    "    \n",
    "    # On vérifie que le lien trouvé n'a pas déjà été analysé sinon l'algorithme va tourner en rond\n",
    "    elif curr_links[-1] in curr_links[:-1]:\n",
    "        print(\"Nous avons déjà rencontré cet article, on arrête là!\")\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Troisième fonction pour trouver l'article philosophie**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_to_philosophy(my_url): \n",
    "    \n",
    "    curr_lst = [my_url]\n",
    "    target_url = \"https://fr.wikipedia.org/wiki/Philosophie\"\n",
    "    \n",
    "    # Tant que la fonction continuer nous indique que True, on continue\n",
    "    while continuer(curr_lst, target_url):\n",
    "        # Article courant\n",
    "        print(curr_lst[-1])\n",
    "        \n",
    "        # Recherche du premier lien sur cet article\n",
    "        first_link = find_first_link(curr_lst[-1])\n",
    "        \n",
    "        if not first_link:\n",
    "            print(\"Nous avons trouvé un lien sans article, on arrête le job!\")\n",
    "            break\n",
    "            \n",
    "        curr_lst.append(first_link)\n",
    "        time.sleep(2) \n",
    "    \n",
    "    print('La distance parcourue entre ces 2 articles est : ' + str(len(curr_lst)-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Main**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "  if len(sys.argv) != 2:\n",
    "    print('usage: ./ex_philosophie_wiki.py start_url')\n",
    "    sys.exit(1)\n",
    "\n",
    "  filename = sys.argv[1]\n",
    "  getting_to_philosophy(filename)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my_url = \"https://fr.wikipedia.org/wiki/Glace\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
